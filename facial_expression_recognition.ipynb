{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_expression_recognition",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKZqeqOfXsA69ZpfmfFOQo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tHbhbHaWOrx",
        "outputId": "cd157867-1071-4994-fcac-e161512d90d6"
      },
      "source": [
        "!git clone https://github.com/muxspace/facial_expressions.git\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'facial_expressions'...\n",
            "remote: Enumerating objects: 14214, done.\u001b[K\n",
            "remote: Total 14214 (delta 0), reused 0 (delta 0), pack-reused 14214\u001b[K\n",
            "Receiving objects: 100% (14214/14214), 239.65 MiB | 42.35 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n",
            "Checking out files: 100% (13996/13996), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70eFV9yrXBl0"
      },
      "source": [
        "import csv\r\n",
        "data={}\r\n",
        "with open('/content/facial_expressions/data/legend.csv') as f:\r\n",
        "  reader=csv.reader(f)\r\n",
        "  next(reader)\r\n",
        "  for row in reader:\r\n",
        "    key=row[2].lower()\r\n",
        "    if key in data:\r\n",
        "      data[key].append(row[1])\r\n",
        "    else:\r\n",
        "      data[key]=[row[1]]\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUs8niqXiudB",
        "outputId": "6dddd9af-7bf5-4b55-aeac-bad60d314822"
      },
      "source": [
        "emotion_list=list(data.keys())\r\n",
        "emotion_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anger',\n",
              " 'surprise',\n",
              " 'disgust',\n",
              " 'fear',\n",
              " 'neutral',\n",
              " 'happiness',\n",
              " 'sadness',\n",
              " 'contempt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-mdDd3Hku8e"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "os.mkdir(\"master_data\")\r\n",
        "os.mkdir(\"master_data/training\")\r\n",
        "os.mkdir(\"master_data/testing\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNKl1BcomPGM"
      },
      "source": [
        "for emotion in emotion_list:\r\n",
        "  os.mkdir(os.path.join(\"master_data/training\",emotion))\r\n",
        "  os.mkdir(os.path.join(\"master_data/testing\",emotion))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ABfZOaUnASX"
      },
      "source": [
        "from shutil import copyfile\r\n",
        "split_size=0.8\r\n",
        "\r\n",
        "for emotion,images in data.items():\r\n",
        "  train_size=int(split_size*len(images))\r\n",
        "  train_images=images[:train_size]\r\n",
        "  test_images=images[train_size:]\r\n",
        "  for image in train_images:\r\n",
        "    source=os.path.join(\"/content/facial_expressions/images\",image)\r\n",
        "    des=os.path.join(\"/content/master_data/training\",emotion,image)\r\n",
        "    copyfile(source,des)\r\n",
        "  for image in test_images:\r\n",
        "    source=os.path.join(\"/content/facial_expressions/images\",image)\r\n",
        "    des=os.path.join(\"/content/master_data/testing\",emotion,image)\r\n",
        "    copyfile(source,des)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUGJEmGAxoo1"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJS77FQ75ETF",
        "outputId": "1b385af2-bf0d-41bf-a6bc-d5fe8b783f82"
      },
      "source": [
        "model=tf.keras.models.Sequential([\r\n",
        "      Conv2D(16,(3,3),activation='relu',input_shape=(100,100,3)),\r\n",
        "      MaxPooling2D(2,2),\r\n",
        "      Conv2D(32,(3,3),activation='relu'),\r\n",
        "      MaxPooling2D(2,2),\r\n",
        "      Conv2D(64,(3,3),activation='relu'),\r\n",
        "      MaxPooling2D(2,2),\r\n",
        "      Flatten(),\r\n",
        "      Dense(256,activation='relu'),\r\n",
        "      Dense(8,activation='softmax')\r\n",
        "])\r\n",
        "model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 98, 98, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 47, 47, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 21, 21, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               1638656   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 1,664,296\n",
            "Trainable params: 1,664,296\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRY3R9RcI7Sx",
        "outputId": "b207775e-e066-4bbb-e1dc-4f766ebdcc3a"
      },
      "source": [
        "train_dir='/content/master_data/training'\r\n",
        "test_dir='/content/master_data/testing'\r\n",
        "\r\n",
        "train_datagen=ImageDataGenerator(rescale=1.0/255)\r\n",
        "train_generator=train_datagen.flow_from_directory(\r\n",
        "    train_dir,\r\n",
        "    target_size=(100,100),\r\n",
        "    class_mode='categorical',\r\n",
        "    batch_size=128\r\n",
        ")\r\n",
        "\r\n",
        "test_datagen=ImageDataGenerator(rescale=1.0/255)\r\n",
        "test_generator=test_datagen.flow_from_directory(\r\n",
        "    test_dir,\r\n",
        "    target_size=(100,100),\r\n",
        "    class_mode='categorical',\r\n",
        "    batch_size=128\r\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10941 images belonging to 8 classes.\n",
            "Found 2742 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISuLi__ULZmM"
      },
      "source": [
        "es=EarlyStopping(monitor='val_acc',patience=2,min_delta=0.01)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH2yMq-OLqmo",
        "outputId": "35a0c0a5-3f9b-4571-e692-5dffc218e616"
      },
      "source": [
        "model.fit_generator(train_generator,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=1,\r\n",
        "                    validation_data=test_generator,\r\n",
        "                    callbacks=[es]\r\n",
        "                    )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "86/86 [==============================] - 15s 174ms/step - loss: 2.2426 - acc: 0.4623 - val_loss: 1.0837 - val_acc: 0.5011\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.9320 - acc: 0.6180 - val_loss: 1.0509 - val_acc: 0.6065\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.7729 - acc: 0.7286 - val_loss: 1.0489 - val_acc: 0.6331\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.6747 - acc: 0.7684 - val_loss: 1.1040 - val_acc: 0.6455\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 15s 172ms/step - loss: 0.6408 - acc: 0.7770 - val_loss: 1.2295 - val_acc: 0.6200\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 15s 171ms/step - loss: 0.6140 - acc: 0.7834 - val_loss: 1.3897 - val_acc: 0.6426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2a467d5b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}